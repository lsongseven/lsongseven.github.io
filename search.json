[{"categories":null,"content":"基于antlr4构建规则引擎简介 1.什么是antlr ANTLR (ANother Tool for Language Recognition) 是一个强大的文本或者二进制文件解析工具，被广泛应用于构建语法以及各种工具和框架。如\n Twitter’s search query language MySQL Workbench Hibernate Trino (SQL query engine) …  antlr可以对某一种语言描述，根据对应的语法，生成一颗语法树，在这颗语法树中包含了语言描述与对应语法规则的关系。当你去遍历这颗语法树时，可以灵活处理遍历前和遍历后的规则，实现某种效果。（可以理解为根据一组确定的语法规则，处理一段数据，如实现某种声明、运算、调用等，从而得到某种结果）\nantlr最新的大版本是v4，了解相关变更详情可参考 Why do we need ANTLR v4\n2.可以用来做什么 antlr可以用来做各种各样的事情，比如本文要说的基于antlr4构建的规则引擎。 除此之外，还有海量的场景可以用到antlr，比如\n vscode中的插件，基于antlr做语法规则检查 grafana中的查询语法解析 格式转换工具，如json、yaml、xml等互相转换 …  3.用antlr4实现类golang语法解析器的规则引擎 最近在研究规则引擎相关的实现，g社上发现一个bilibili的开源项目gengine，基于antlr4实现了类golang的语法解析器，下面我们来以gengine为例看一下如何基于antlr4实现这个事情。\n下面文件中描述了一个规则的表达，其中具体的规则部分表达与golang语法基本类似。这个就是在gengine中规则描述的基本形式，在gengine中，用户可以根据具体的场景构造若干个规则，通过这个规则去做一些事情。下面的描述中， rule为固定的规则描述声明词，“rulename” “rule-description” 为规则的名称和描述，salience为固定的规则优先级描述声明词，后面的10代表这个规则的优先级为10。begin和end中包围的部分为具体的规则内容，在gengine中其表达方式类似于golang的语法。\n1 2 3 4 5 6  rule \"rulename\" \"rule-description\" salience 10 begin //规则体 end   对应的antlr4中的语法描述文件(gengine.g4，为了展示方便省略了部分内容，全部内容可通过链接查看)如下，具体的.g4文件结构可参考 Grammer Structure\ngrammar gengine; primary: ruleEntity+; ruleEntity: RULE ruleName ruleDescription? salience? BEGIN ruleContent END; ruleName : stringLiteral; ruleDescription : stringLiteral; salience : SALIENCE integer; ruleContent : statements; statements: statement* returnStmt? ; statement : ifStmt | functionCall | methodCall | threeLevelCall | assignment | concStatement | forStmt | breakStmt |forRangeStmt | continueStmt; concStatement : CONC LR_BRACE ( functionCall | methodCall | threeLevelCall | assignment )* RR_BRACE; expression : mathExpression | expression comparisonOperator expression | expression logicalOperator expression | notOperator ? expressionAtom | notOperator ? LR_BRACKET expression RR_BRACKET ; mathExpression : mathExpression mathMdOperator mathExpression | mathExpression mathPmOperator mathExpression | expressionAtom | LR_BRACKET mathExpression RR_BRACKET ; expressionAtom : functionCall | methodCall | threeLevelCall | constant | mapVar | variable ; assignment : (mapVar | variable) assignOperator (mathExpression| expression); returnStmt : RETURN expression?; ifStmt : IF expression LR_BRACE statements RR_BRACE elseIfStmt* elseStmt? ; elseIfStmt : ELSE IF expression LR_BRACE statements RR_BRACE; elseStmt : ELSE LR_BRACE statements RR_BRACE; functionArgs : (constant | variable | functionCall | methodCall | threeLevelCall | mapVar | expression) (','(constant | variable | functionCall | methodCall | threeLevelCall | mapVar | expression))* ; integer : MINUS? INT; realLiteral : MINUS? REAL_LITERAL; stringLiteral: DQUOTA_STRING ; booleanLiteral : TRUE | FALSE; functionCall : SIMPLENAME LR_BRACKET functionArgs? RR_BRACKET; variable : SIMPLENAME | DOTTEDNAME | DOUBLEDOTTEDNAME; mathPmOperator : PLUS | MINUS ; mathMdOperator : MUL | DIV ; comparisonOperator : GT | LT | GTE | LTE | EQUALS | NOTEQUALS ; assignOperator: ASSIGN | SET | PLUSEQUAL | MINUSEQUAL | MULTIEQUAL | DIVEQUAL ; // ... fragment DEC_DIGIT : [0-9]; fragment A : [aA] ; fragment B : [bB] ; fragment C : [cC] ; // ... fragment Z : [zZ] ; fragment EXPONENT_NUM_PART : ('E'| 'e') '-'? DEC_DIGIT+; NIL : N I L; RULE : R U L E ; AND : '\u0026\u0026' ; OR : '||' ; CONC : C O N C; IF : I F; ELSE : E L S E; RETURN : R E T U R N; // ... BEGIN : B E G I N; END : E N D; SIMPLENAME : ('a'..'z' |'A'..'Z'| '_')+ ( ('0'..'9') | ('a'..'z' |'A'..'Z') | '_' )* ; INT : '0'..'9' + ; PLUS : '+' ; MINUS : '-' ; DIV : '/' ; MUL : '*' ; EQUALS : '==' ; GT : '\u003e' ; LT : '\u003c' ; GTE : '\u003e=' ; // ... SEMICOLON : ';' ; LR_BRACE : '{'; RR_BRACE : '}'; LR_BRACKET : '('; RR_BRACKET : ')'; DOT : '.' ; DQUOTA_STRING : '\"' ( '\\\\'. | '\"\"' | ~('\"'| '\\\\') )* '\"'; DOTTEDNAME : SIMPLENAME DOT SIMPLENAME ; DOUBLEDOTTEDNAME : SIMPLENAME DOT SIMPLENAME DOT SIMPLENAME; REAL_LITERAL : (DEC_DIGIT+)? '.' DEC_DIGIT+ | DEC_DIGIT+ '.' EXPONENT_NUM_PART | (DEC_DIGIT+)? '.' (DEC_DIGIT+ EXPONENT_NUM_PART) | DEC_DIGIT+ EXPONENT_NUM_PART ; SL_COMMENT: '//' .*? '\\n' -\u003e skip ; WS : [ \\t\\n\\r]+ -\u003e skip ; 上述.g4文件声明了gengine中依赖的语法规则。按照这种语法规则，假设当前有以下一段输入\n1 2 3 4 5 6 7 8 9 10 11 12 13  rule \"elseif_test\" \"test\" begin a = 8 if a \u003c 1 { println(\"a \u003c 1\") } else if a \u003e= 1 \u0026\u0026 a \u003c6 { println(\"a \u003e= 1 \u0026\u0026 a \u003c6\") } else { println(\"a \u003e= 6\") } end   根据gengine.g4文件中提供的语法规则，antlr4将输入内容组织成一颗语法树，语法树的结构可见下图。遍历这颗语法树，可以获得对应的语法树结构，这是实现规则引擎的基础。\n下面谈一下antlr4是如何做到这个事情的。可以通过如下命令来解析.g4文件，执行之后生成了几种类型的文件\n1 2 3  $ wget \u003chttp://www.antlr.org/download/antlr-4.7-complete.jar\u003e $ alias antlr4='java -jar $PWD/antlr-4.7-complete.jar' $ antlr4 -Dlanguage=Go -o parser gengine.g4   A. lexer\nlexer的作用是将任意的文本输入返回为一系列token，如上述例子中假设输入为 a \u003c 1 , lexer会返回SIMPLENAME(a), LT(\u003c), INT(1)\nB. parser\nparser的作用是接受lexer的输出并将其用于语法规则(rule)，构造更高级别的结构，比如将expression赋值给variable。\nC. listener\n经过parser，我们的输入已经成为了一个符合.g4文件中语法的语法树，listener的作用就是提供了遍历节点前和节点后的hooks，这些hooks中具体的函数要使用者根据具体的场景去实现。\n遍历语法树后，我们可以得到一个与语法树对应的规则结构体，而这个结构体可以是规则引擎中的某个规则，规则可以实现func (r RuleEntity) Execute(dccontext.DataContext) (interface{}, error, bool) 方法来实现具体规则的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  // 遍历语法树后得到的规则结构体，部分字段已忽略  type RuleEntity struct { RuleName string Salience int64 RuleDescription string RuleContent *RuleContent } type RuleContent struct { Statements *Statements } type Statements struct { StatementList []*Statement // ... } type Statement struct { IfStmt *IfStmt FunctionCall*FunctionCall Assignment *Assignment // ... } type IfStmt struct { Expression *Expression StatementList*Statements ElseIfStmtList []*ElseIfStmt ElseStmt*ElseStmt } type Expression struct { SourceCode ExpressionLeft *Expression ExpressionRight*Expression ExpressionAtom *ExpressionAtom MathExpression*MathExpression LogicalOperator string ComparisonOperator string NotOperator string } // ...  type ElseIfStmt struct { Expression *Expression StatementList*Statements }   以IfStmt为例，简单介绍下在Execute中所做的事情。其实所做的事情很简单，就是正常的if逻辑，只不过在golang中用反射和语法树结构的下层调用表达出来，其中 dc *context.DataContext 与 Vars map[string]reflect.Value 中存放了变量的值，如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  func (i*IfStmt) Evaluate(dc *context.DataContext, Vars map[string]reflect.Value) (reflect.Value, error, bool) { it, err := i.Expression.Evaluate(dc, Vars) if err != nil { return reflect.ValueOf(nil), err, false } // if 条件命中  if it.Bool() { if i.StatementList == nil { return reflect.ValueOf(nil), nil, false } else { return i.StatementList.Evaluate(dc, Vars) } } else { // else if 条件判断  if i.ElseIfStmtList != nil { for _, elseIfStmt := range i.ElseIfStmtList { v, err := elseIfStmt.Expression.Evaluate(dc, Vars) if err != nil { return reflect.ValueOf(nil), err, false } // else if 条件命中  if v.Bool() { return elseIfStmt.StatementList.Evaluate(dc, Vars) } } } // else 条件判断  if i.ElseStmt != nil { return i.ElseStmt.Evaluate(dc, Vars) } else { return reflect.ValueOf(nil), nil, false } } }   现在知道规则如何跑起来，思考的另一个事情是参数如何传递。因为以规则引擎为例，想做的事情可以概括为在某种条件某种规则约束下对应的输出的是什么。输入必须是动态的，这样某个规则才有存在的意义。gengine提供了注入外部变量和函数的方式来实现这个事情, 使用的方式如下\n1 2 3 4 5 6 7  // 注入外部变量或者函数 dataContext := context.NewDataContext() dataContext.Add(\"println\", fmt.Println) dataContext.Add(\"a\",20) v, err, bx := rule.Execute(dataContext) // ...   到这里似乎基于antlr4构建规则引擎的事情就做完了，用户可以随意声明一段规则，然后基于规则去做对应的业务判断。antlr4帮助我们做的其实是将输入文本转换为一个根据.g4文件的语法树，具体要怎么用这个语法树就是使用者应该考虑的事情，在规则引擎这个范畴下，可以参考gengine对应的实现。另外，可以参考他们的test，里面有很多不同的用法。\n4.参考   https://www.antlr.org/\n  https://blog.gopheracademy.com/advent-2017/parsing-with-antlr4-and-go/\n  https://github.com/bilibili/gengine\n  ","description":"","tags":null,"title":"基于antlr4构建规则引擎简介","uri":"/posts/antlr4/"},{"categories":null,"content":"Distributed Tracing System Preface  Trace有什么用  从最早期的巨石单体（Monolithic）到分布式（Distributed），再到微服务（Microservices）、容器化（Containerization）、容器编排（Container Orchestration），最后到服务网格（Service Mesh）、无服务器（Serverless）,复杂度不断提升，问题定位越来越复杂\n Trace可以快速定位问题 + 理清网络拓扑  OpenTracing OpenTracing是业务、框架等代码与分布式追踪实现厂商（如jaeger、zipkin、skywalking）之间的一层标准层。OpenTracing通过提供平台无关、厂商无关的API，使得开发人员能够方便的添加（或更换）追踪系统的实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  +-------------+ +---------+ +----------+ +------------+ | Application | | Library | | OSS | | RPC/IPC | | Code | | Code | | Services | | Frameworks | +-------------+ +---------+ +----------+ +------------+ | | | | | | | | v v v v +-----------------------------------------------------+ | · · · · · · · · · · OpenTracing · · · · · · · · · · | +-----------------------------------------------------+ | | | | | | | | v v v v +-----------+ +-------------+ +-------------+ +-----------+ | Tracing | | Logging | | Metrics | | Tracing | | System A | | Framework B | | Framework C | | System D | +-----------+ +-------------+ +-------------+ +-----------+    Terminology: Trace, Span  一个trace代表一个潜在的，分布式的，存在并行数据或并行执行轨迹（潜在的分布式、并行）的系统。Trace由Span组成，可以看作是一个由Span组成的有向无环图(Directed Acyclic Graph)， Span之间的边被称为Refrence。\n一个Span代表系统中具有开始时间和执行时长的逻辑运行单元。Span之间通过嵌套或者顺序排列建立逻辑因果关系。\n Span之间的关系 ChildOf : 一个span可能是一个父级span的孩子，即\"ChildOf\"关系。在\"ChildOf\"引用关系下，父级span某种程度上取决于子span。 FollowsFrom: 一些父级节点不以任何方式依然他们子节点的执行结果，这种情况下，我们说这些子span和父span之间是\"FollowsFrom\"的因果关系。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  Causal relationships between Spans in a single Trace [Span A] ←←←(the root span) | +------+------+ | | [Span B] [Span C] ←←←(Span C is a `ChildOf` Span A) | | [Span D] +---+-------+ | | [Span E] [Span F] \u003e\u003e\u003e [Span G] \u003e\u003e\u003e [Span H] ↑ ↑ ↑ (Span G `FollowsFrom` Span F)   1 2 3 4 5 6 7 8 9 10  Temporal relationships between Spans in a single Trace ––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–\u003e time [Span A···················································] [Span B··············································] [Span D··········································] [Span C········································] [Span E·······] [Span F··] [Span G··] [Span H··]    OpenTracing中Span的定义包括  操作的名称 开始时间戳 结束时间戳 Span Tags Span Logs SpanContext  每个span必须提供方法访问SpanContext，包含\u003ctrace_id, span_id, sampled\u003e元组 跨越进程依赖于OpenTracing的Inject/Extract 跨越进程边界，封装Baggage Items   Baggage Item  Baggage是存储在SpanContext中的一个键值对(SpanContext)集合。它会在一条追踪链路上的所有Span内全局传输，包含这些Span对应的SpanContexts   与此Span相关联的其他Span的引用    传递上下文的一个案例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  import ( \"net/http\" opentracing \"github.com/opentracing/opentracing-go\" \"github.com/opentracing/opentracing-go/ext\" ) ... tracer := opentracing.GlobalTracer() clientSpan := tracer.StartSpan(\"client\") defer clientSpan.Finish() url := \"http://localhost:8082/publish\" req, _ := http.NewRequest(\"GET\", url, nil) // Set some tags on the clientSpan to annotate that it's the client span. The additional HTTP tags are useful for debugging purposes. ext.SpanKindRPCClient.Set(clientSpan) ext.HTTPUrl.Set(clientSpan, url) ext.HTTPMethod.Set(clientSpan, \"GET\") // Inject the client span context into the headers tracer.Inject(clientSpan.Context(), opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(req.Header)) resp, _ := http.DefaultClient.Do(req)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  import ( \"log\" \"net/http\" opentracing \"github.com/opentracing/opentracing-go\" \"github.com/opentracing/opentracing-go/ext\" ) func main() { // Tracer initialization, etc.  ... http.HandleFunc(\"/publish\", func(w http.ResponseWriter, r *http.Request) { // Extract the context from the headers  spanCtx, _ := tracer.Extract(opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(r.Header)) serverSpan := tracer.StartSpan(\"server\", ext.RPCServerOption(spanCtx)) defer serverSpan.Finish() }) log.Fatal(http.ListenAndServe(\":8082\", nil)) }   Jaeger vs. Skywalking Architecture  Client: 实现了OpenTracing API的客户端，用于增强业务代码。 Agent: 监听UDP发来的Span数据，可部署为sidecar或者DaemonSet，屏蔽client与collector之间的路由和服务发现细节 Collector 将采集到的 trace 数据写入中间缓冲区 Kafka 中，Ingester 读取 Kafka 中的数据并持久化到 DB 里。同时，Flink jobs 持续读取 Kafka 中的数据并将计算出的拓扑关系写入 DB 中。 Sampling: Constant, Probabilistic, Rate Limiting, Remote   Observability Analysis Platform (OAP)  [*] why doesn’t skywalking involve mq in its architecture\nEnhancement  skywalking 依靠字节码增强技术，可依赖一个agent类来实现特定的增强。这个agent类需要实现void premain(String agentArgs, Instrumentation instrumentation)这样一个方法，具体的增强细节涵盖在其中。（Java中广泛使用的技术，如rpc框架dubbo、诊断工具arthas等）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // java -javaagent:xxx.jar -jar yy.jar  /** * The main entrance of sky-walking agent, based on javaagent mechanism. */ public class SkyWalkingAgent { /** * Main entrance. Use byte-buddy transform to enhance all classes, which define in plugins. */ public static void premain(String agentArgs, Instrumentation instrumentation) throws PluginException { // instrument  ... } }    SDK  Cloud Native Refrence   https://opentracing.io/docs/\n  https://wu-sheng.gitbooks.io/opentracing-io/content/\n  https://eng.uber.com/distributed-tracing/\n  https://medium.com/opentracing/towards-turnkey-distributed-tracing-5f4297d1736\n  ","description":"","tags":null,"title":"Distributed Tracing System","uri":"/posts/distributed-tracing-system/"},{"categories":null,"content":"Hello, 我是一个毕业自上海交通大学，现效力于某不知名公司，热爱技术，喜欢钻研的coder\nTalk is cheap. Show me the code.\n欢迎联系 lsongseven@gmail.com , 相互指教\n","description":"","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"以container_memory_usage_bytes作为memory指标 过去的一段时间内，xxx服务在prometheus上面用来监控内存的指标是以容器内存使用量（率）来衡量的，如下：\ncontainer_memory_usage_bytes{pod=~\"xxx.*-[^-]*-[^-]*$\", image!=\"\", container!=\"POD\"}*100/container_spec_memory_limit_bytes{pod=~\"xxx.*-[^-]*-[^-]*$\", image!=\"\", container!=\"POD\"} \u003e 80.0 xxx服务在kubernetes中的资源配置情况如下，\nresources: limits: cpu: \"2\" memory: \"4Gi\" requests: cpu: \"100m\" memory: \"512Mi\" 在这样的配置下，上面监控rule的语义就是，当容器内使用内存量达到容器最大内存（4G）的80%时发出告警。\n再来看下container_memory_usage_bytes如何定义，在cadvisor上面一个issue中提到：\ncontainer_memory_usage_bytes == container_memory_rss + container_memory_cache + container_memory_swap + kernel memory(issue中提到这里的kernel memory还未被暴露为metrics).\n看到rss, swap, cache这些指标很自然的就想到top，在top中也有一个指标叫做used，其定义为 ：“USED - simply the sum of RES and SWAP”, https://man7.org/linux/man-pages/man1/top.1.html\n以container_memory_usage_bytes作为java容器内存指标的问题 频繁告警 某刻xxx服务中某个pod中top指标如下\ntop - 05:35:43 up 7 days, 21:32, 0 users, load average: 11.99, 11.35, 8.50 Tasks: 10 total, 1 running, 9 sleeping, 0 stopped, 0 zombie %Cpu(s): 6.7 us, 6.5 sy, 0.0 ni, 85.9 id, 0.3 wa, 0.0 hi, 0.7 si, 0.0 st KiB Mem : 65960736 total, 7194880 free, 42443524 used, 16322332 buff/cache KiB Swap: 0 total, 0 free, 0 used. 19621872 avail Mem PID %MEM RES VIRT SHR SWAP CODE COMMAND 9 6.0 3.8g 9833416 16400 0 4 java 107812 0.0 2140 59728 1504 0 96 top 69248 0.0 2152 59716 1504 0 96 top 57442 0.0 2152 59712 1504 0 96 top 57423 0.0 2992 16160 1624 0 888 bash 68879 0.0 2928 16160 1564 0 888 bash 107795 0.0 2936 16160 1568 0 888 bash 68899 0.0 3000 16156 1628 0 888 bash 1 0.0 2548 16020 1328 0 888 bash 107946 0.0 476 7876 280 0 24 sleep 可以看到我们的9号java进程，RES占用有3.8GB，而前面说过，USED=RES+SWAP，这里还没有发生SWAP，所以USED等于RES占用了3.8GB。在我们的告警规则中，配置了当容器内存达到最大值4GB的80%时发生告警，即容器内USED \u003e 3.2GB时会告警，容器内最重要java进程自己的USED就远大于这个阈值，所以会频繁告警。\n那么，RES为3.8GB有什么问题呢？\nJVM指标 既然是java进程常驻内存很高，那么首先怀疑的就是jvm内存占用问题。\n看一下堆内存，jmap -heap 9，发现很健康\nHeap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 3221225472 (3072.0MB) NewSize = 1073741824 (1024.0MB) MaxNewSize = 1073741824 (1024.0MB) OldSize = 2147483648 (2048.0MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 859832320 (820.0MB) used = 483407288 (461.0131149291992MB) free = 376425032 (358.9868850708008MB) 56.22111157673161% used From Space: capacity = 106954752 (102.0MB) used = 50262824 (47.934364318847656MB) free = 56691928 (54.065635681152344MB) 46.99447482239966% used To Space: capacity = 106954752 (102.0MB) used = 0 (0.0MB) free = 106954752 (102.0MB) 0.0% used PS Old Generation capacity = 2147483648 (2048.0MB) used = 143595616 (136.94345092773438MB) free = 2003888032 (1911.0565490722656MB) 6.68669193983078% used 不信邪手动gc一下，发现RES并没有什么变化。\njcmd 9 GC.run 到这里可以明白堆内内存没有什么问题，下一个怀疑对象是堆外内存。启动参数上加上-XX:NativeMemoryTracking=summary，然后jcmd 9 VM.native_memory summary scale=MB看一下发现依然很健康（虽然加上参数容器会重启，但下面数据也是在频繁告警的情况下获得的）\nNative Memory Tracking: Total: reserved=5261MB, committed=4124MB - Java Heap (reserved=3072MB, committed=3072MB) (mmap: reserved=3072MB, committed=3072MB) - Class (reserved=1180MB, committed=174MB) (classes #25539) (malloc=12MB #47472) (mmap: reserved=1168MB, committed=162MB) - Thread (reserved=535MB, committed=535MB) (thread #531) (stack: reserved=532MB, committed=532MB) (malloc=2MB #2660) (arena=1MB #1057) - Code (reserved=274MB, committed=144MB) (malloc=30MB #29634) (mmap: reserved=244MB, committed=113MB) - GC (reserved=122MB, committed=122MB) (malloc=10MB #615) (mmap: reserved=112MB, committed=112MB) - Compiler (reserved=1MB, committed=1MB) (malloc=1MB #3104) - Internal (reserved=40MB, committed=40MB) (malloc=40MB #38278) - Symbol (reserved=30MB, committed=30MB) (malloc=26MB #267011) (arena=4MB #1) - Native Memory Tracking (reserved=6MB, committed=6MB) (tracking overhead=6MB) 与前文的堆内内存相比较，容易发现这里所指的committed即capacity，那么offsetHeap的capacity=174+535+144+122+1+40+30+6 MB = 1052 MB，注意这里仅为committed(或者可以理解成capacity)，实际使用肯定是要小于这个值的，那么再考虑到前面heap的实际使用情况461+47+136 MB = 644 MB， 以上两者(heap+offsetHeap)之和肯定是要远远小于3.8g的。\n这里可以根据到这里可以发现jvm很健康，内存占用是比较低的。那么，top命令中的RES究竟是什么呢？\n重新考量top 写到这里啰嗦了一大堆，前面的逻辑简单概括一下：\n使用了cadvisor里面的container_memory_usage_bytes作为指标参数，而这个指标和top强相关，都是RES+SWAP+一些其他东西（占用很小）； 在我们应用中没有发生swap，所以造成告警的原因主要是java进程的RES很大； java进程内部堆内内存和堆外内存很健康，没有看到大量占用内存的迹象； 不得不说top是一个很强大的工具，但是他也有很多的诟病，尤其是对于java进程来说，下面摘录一些国外开发者的抱怨：\n“It really annoys me that there’s no good tool for measuring memory usage on Linux. There are tools, like ‘top’, but they often cause more harm than good - most people don’t even know what the fields really mean and only few people can interpret them correctly. Mind you, even I’m not sure I can, and in fact I sometimes doubt such person even exists. The problem is, even intepreting the numbers may not give the answer. Measuring memory usage on Linux is voodoo magic.\"\n– from https://blogs.kde.org/node/1445\n“This has been a long-standing complaint with Java, but it’s largely meaningless…With a Java program, it’s far more important to pay attention to what’s happening in the heap. The total amount of space consumed is important, and there are some steps that you can take to reduce that. More important is the amount of time that you spend in garbage collection, and which parts of the heap are getting collected.\"\n– from https://stackoverflow.com/questions/561245/virtual-memory-usage-from-java-under-linux-too-much-memory-used\n最后的观点就是，对于java进程来说，我们的关注点不应该是RES，而应该将目光转向heap。查阅很多资料后，能找到的关于这个现象下RES高的最贴切的解释是下面的一段话：\nWhen is Resident Set Size Important?\nResident Set size is that portion of the virtual memory space that is actually in RAM. If your RSS grows to be a significant portion of your total physical memory, it might be time to start worrying. If your RSS grows to take up all your physical memory, and your system starts swapping, it’s well past time to start worrying.\nBut RSS is also misleading, especially on a lightly loaded machine. The operating system doesn’t expend a lot of effort to reclaiming the pages used by a process. There’s little benefit to be gained by doing so, and the potential for an expensive page fault if the process touches the page in the future. As a result, the RSS statistic may include lots of pages that aren’t in active use.\n根据上面这段话，可以看出只有在发生了swap的时候，RES（上文中用RSS表示，二者意义相同）很高才会变得重要，这个时候要考虑是不是有memory leaking这种事情或者其他的情况。在一些轻负载并且尚未发生swap的场景下，高RES占用并不能说明什么问题，可能只是操作系统在reclaiming pages和效率之间的一个权衡，RES中统计的很多内存可能并不是真正在使用。\n结论 放弃容器级别的metrics转向jvm级别\n","description":"","tags":null,"title":"Java进程容器内存监控指标","uri":"/posts/java-container-metrics/"},{"categories":null,"content":"优雅退出 这一篇是为了解决引入buffer后，如何保证数据不丢失？\n简单介绍一下问题，如下图，通过open api传入的message会在buffer中囤积到一定量后进行处理，引入buffer是为了减少mysql的压力，减少对于数据库的频繁读写。但是由于buffer是内存中的一个数据结构，那么如何保证数据不丢失呢？\n数据丢失的情况可能发生于：（1）升级部署时；（2）pod重启时；（3）极端情况，如断电等。\n在公有云情况下，可以先忽略极端情况，云服务商会有一定的保障策略。因此只需要把目光聚集到（1）和（2）两点。 其实可以业界有很多可以参考的例子，比如mysql的redo log和redis的aof都可以一定程度保证在发生问题的时候数据的完整性，但是如果在我们的服务中实现这样的东西太重了，个人认为其实保障数据完整性是一个很通用的需求，应该会有一些开源的项目支持（但是没有找到，不过我认为这是一个赚star的好机会）。\n回到主要问题，考虑到我们的服务都是java的服务，有一种简单的方法可以实现在应用退出的时候优雅停机：使用java提供的shutdown hook来做这个事情（在spring boot中也有类似的东西，通过@PreDestroy注解来实现，不过追到底还是shutdown hook），当jvm收到退出的信号时，调用shutdown hook内的方法，完成清理操作。\nshutdown hook可以保证在应用主动关闭、代码中调用System#exit、OOM、终端Ctrl+C等情况下被调用，对于我们看重的（1）（2）来说，可以很好的解决问题，举个例子增加如下hook：\nRuntime.getRuntime().addShutdownHook(new Thread(() -\u003e System.out.println(“shutdown hook!\"))); 在退出时会在终端打印出 “shutdown hook!\"。在实际使用中，可以对将对buffer清理的动作加到hook中，于是可以保证优雅退出。\n可是，这样就完了吗？\n在kubernetes中优雅停机 在本地java -jar xxx.jar运行一个java程序后，通过kill pid这种方式可以完美实现优雅退出，但是到了ecp上，情况并不是这么回事。在每次重新部署的时候，发现并没有触发shutdown hook，问题出在哪里呢？\n这个要从kubernetes中pod关闭说起，参照 https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n User sends command to delete Pod, with default grace period (30s) The Pod in the API server is updated with the time beyond which the Pod is considered “dead” along with the grace period. Pod shows up as “Terminating” when listed in client commands (simultaneous with 3) When the Kubelet sees that a Pod has been marked as terminating because the time in 2 has been set, it begins the Pod shutdown process. a. If one of the Pod’s containers has defined a preStop hook, it is invoked inside of the container. If the preStop hook is still running after the grace period expires, step 2 is then invoked with a small (2 second) one-time extended grace period. You must modify terminationGracePeriodSeconds if the preStop hook needs longer to complete. b. The container is sent the TERM signal. Note that not all containers in the Pod will receive the TERM signal at the same time and may each require a preStop hook if the order in which they shut down matters. (simultaneous with 3) Pod is removed from endpoints list for service, and are no longer considered part of the set of running Pods for replication controllers. Pods that shutdown slowly cannot continue to serve traffic as load balancers (like the service proxy) remove them from their rotations. When the grace period expires, any processes still running in the Pod are killed with SIGKILL. The Kubelet will finish deleting the Pod on the API server by setting grace period 0 (immediate deletion). The Pod disappears from the API and is no longer visible from the client.  这里4.a中提到的preStop hook先不去管他，这是kubernetes提供的一种优雅停机方式。可以看到在4.b中，container会被发送TERM signal，而按照常理来说，如果我们的java进程收到这个TERM信号，那么就会优雅退出，shutdown hook就会执行。可是现实并没有按照我们想要的进行流转，问题就出在这个TERM信号这里。\nENTRYPOINT中的startup.sh 仔细查看我们的Dockerfile，大概的样式如下：\n#Dockerfile ... ENTRYPOINT [\"bash\",\"./startup.sh\"] #startup.sh ... nohup java $JAVA_OPTS -jar ./xxx.jar --server.port=8080 \u0026 while true do sleep 2 done 这样做的问题是什么呢？\n可以先看一个例子，在容器中，输入ps -ef可以得到\n[root@xxx-74bc7c554d-vvz4w envuser]# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 Jul15 ? 00:00:32 bash ./startup.sh root 10 1 4 Jul15 ? 02:19:06 java -Xmx3072m,output=tcpse root 94141 0 1 02:55 pts/0 00:00:00 bash root 94157 1 0 02:55 ? 00:00:00 sleep 2 root 94158 94141 0 02:55 pts/0 00:00:00 ps -ef 可以看到，1号进程是我们的bash ./startup.sh，而10号进程是真正服务所在的java进程，并且他是1号进程的子进程。问题就在这里，在pod关闭时，TERM信号只会发送给1号进程，而1号进程并不会将此TERM信号转发到下面的子进程，由此java进程收不到TERM信号，那么也就无法触发shutdown hook，无法优雅退出（最终应该时通过kill -9 pid这种方式退出的）。\n那么现在的问题就在于如何将TERM信号传到java进程上，有两种方法：\n第一种，使用在startup.sh中，使用下面的方式启动java进程，这里exec的作用是使java进程取代当前的bash进程作为1号进程，那么当TERM信号发送给1号进程的时候自然能够优雅退出。但是，这会带来一些问题，我们后面再说。\n#startup.sh ... exec java $JAVA_OPTS -jar ./xxx.jar --server.port=8080 第二种，也是推荐的一种，在startup.sh中利用trap捕获TERM信号，将其传递给下面的子进程，如下所示，至于为什么这么写，有一篇很好的参考文献 http://veithen.io/2014/11/16/sigterm-propagation.html：\n#startup.sh ... trap 'kill -TERM $child' TERM nohup java $JAVA_OPTS -jar ./xxx.jar --server.port=8080 \u0026 child=$! wait $child wait $child 为什么不推荐java进程作为1号进程 上面的两种方式里，说到了不推荐第一种方式，为什么呢？\n这要涉及到unix系统中1号进程的特殊作用：1号进程会作为孤儿进程的父进程，同时会需要有收割清理的功能，避免系统产生僵尸进程。对于bash来说，比较完备了，可以很好的adop and reap，然而对于用户写的java进程来说，一般不会考虑到收割清理这种功能，所以如果将java进程作为1号进程的话，容易产生僵尸进程。\n举个例子：\njava (1) -\u003e A process (10)，代表10号进程A process是1号java进程的子进程，当A process 终结的时候，会发送SIGCHILD信号唤醒java进程，期待其进行收割。但是假如java进程没有特殊的处理然后不理会这个信号，那么A process将会成为一个zombie process，即虽然已经终结了，但是依然占据一部分资源，这不是我们所希望看到的。\n因此，推荐使用第二种方式，将bash作为1号进程，这样不必担心zombie process的问题。\n这里再推荐一篇极佳的参考 https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/, 极力推荐大家读一读。\n最后再说一下while loop的问题 在前面之前的startup.sh里面，可以看到最后面有一个while循环，有没有想过为什么要加这个东西？\n其实根源在于它的上一句通过nohup … \u0026的方式启动了java进程，如果不在最后进行loop，那么startup.sh就会执行完毕而退出，带来的问题就是pod的状态变为completed的状态，也就是说pod认为任务已经执行完毕而自动退出了。作为一个web server端来说，肯定不能让他退出啊，所以在这里采用了while循环来阻止进程退出。不过这是历史问题了，在第二种startup.sh中，trap wait机制会阻塞进程直到子进程退出，因此后面也就不需要while loop这种东西了。最后再留个问题，为什么要两遍wait $child ?那篇参考文献中讲的很详细了 : )\n","description":"","tags":null,"title":"如何在kubernetes中优雅停机","uri":"/posts/shutdownhook/"},{"categories":null,"content":"Eviction Policy 在caffeine中缓存的管理使用的是Window TinyLFU(W-TinyLFU)的技术，结构如下图\n先来解释一下各个部分：\nwindow cache（绿色部分）: 新对象存入的区域；考虑到缓存的驱逐策略是基于类似LFU的粗略，这里的window cache是对新加入对象的一个保护策略，这些对象会现在window cache中呆一段时间，然后累积一定的frequency之后（LRU策略将其淘汰的时候）才会到TinyLFU中与其他缓存进行frequency的battle，决定去留； main cache （红色和蓝色部分）：大部分缓存所在的区域； TinyLFU (紫色部分，一个admission filter）：当window cache空间存满之后，来自window cache区域的victim将会和来自main cache区域的victim进行比较，判断二者出现频率的大小，如果前者更大，那么将会将前者插入main cache，淘汰掉后者；反之，淘汰掉前者；\n下面这个图可以更好的帮助了解Window TinyLFU的过程\n在caffeine中，window cache所占大小约为总cache大小的1%，这是一个调参之后的结果，Window TinyLFU的作者做过大量实验证明在大多数的情况下1%能够实现缓存的最大命中率。\n在TinyLFU中，使用count min sketch的方式来进行频率的估算，所谓count min sketch，就是利用多个哈希函数来对某个对象的频率进行计数，然后在计算这个对象的频率时，选择最小的哈希函数的计数值最为他的频率（这里可以考虑一种在单一哈希函数下的一个场景，如果有一个热键，他出现的频率很高，哈希之后的键位h1，然后又有一个很冷的键，出现的频率很低，然而由于哈希函数的碰撞其哈希之后的键也为h1，那么这就会造成很难淘汰这个冷键。这里采用多个哈希函数可以很好的规避这种情况）。\ncount min sketch的结构如下图：\n在TinyLFU中，为了使缓存能够有一定的“鲜活性”，在每一次access的时候都会将缓存技术乘以一个aging factor（默认为2），这样的一个操作被称为“Reset”。这样做的好处是可以规避掉历史的“惯性”，举个例子，比如在视频网站上之前一个很火的剧，被点击了上亿次，如果不加以aging的措施的话，可能会一直霸榜，这不是我们希望看到的。\n下面再来说一下main cache部分，采用的是Segmented LRU策略，即SLRU。其中会有两个部分：\nprotected，这部分的对象比较安全，但是如果protected队列满了之后会将lru淘汰入probation队列。 probation，这部分的对象较为危险，如果probation队列满了之后会淘汰lru的对象，但是如果这部分中的对象又再次被访问之后此对象会升级进入protected队列。\nExpiration Policy caffeine中的过期策略有两种，分别是fixed expiration policy和variable expiration policy，下面进行简单介绍。\n对于定时过期策略（fixed expiration policy）而言，为每个队列设置一个固定的过期时间（expire after access，expire after write）如60s，同时可维护一个LRU队列，靠近head端的对象为更老的对象，靠近tail端的对象为更新的对象。当某个对象过期时，head朝向tail端移动，这样在进行过期对象清理的时候head左边的对象就是需要清理的，整个操作复杂度在O(1)级别。\n对于可变过期时间策略(variable expiration policy), 每个对象的过期时间可能不尽相同，caffeine引入时间轮来对此进行操作。关于时间轮的概念可参考kafka中时间轮的设计。\n简单来说，就是利用一个定长数组，每个元素代表一定的时间范围，对应过期时间的缓存对象以双链表的形式存储在这个时间格上。当时间轮转过一圈时，上面一层时间轮每个元素代表的时间范围会是 原始的时间范围x数组元素个数。当时间推动时，时间指针指向的时间格中的对象会被进行过期操作，同时其上层时间轮对应的时间格上的对象会被重新hash填入下层时间轮中。原理其实很简单，可以和生活中的钟表的结构进行类比。\n参考文献 https://dl.acm.org/doi/pdf/10.1145/3274808.3274816\nhttp://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html\nhttp://highscalability.com/blog/2019/2/25/design-of-a-modern-cachepart-deux.html\n","description":"","tags":null,"title":"Caffeine内存缓存","uri":"/posts/caffeine/"},{"categories":null,"content":"最近遇到的一个问题是，在更换了https的加密协议后（从ssl更换到tls），之前的post请求总是返回400 bad request这样的问题。网上搜罗了一下，有很多人遇到同样的400 bad request，但是各自的具体情况不尽相同，因此没有找到有效的解决方法。\n先说一下遇到的情况，对于某一个post请求，在postman中访问没有问题，但是在java代码中使用httpclient按照原先使用正常的方式去做请求，返回的response为一个null，没有其他具体信息，很难追溯。没有办法，只能一步一步跟进调试，一直跟到org.apache.http.impl.execchain包下MainClientExec.class这个类中，并且可以看到请求是正常发送出去，但是收到的response是null。由于对https的了解不是很足，起初怀疑是不是由于更换到tls后握手出现问题，于是调整org.apache.http这个包下的日志等级为debug，可以看到连接是正常建立，因此排除握手的问题。\n2020-03-19 16:10:35,119 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:423)]-[DEBUG] Secure session established 2020-03-19 16:10:35,119 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:424)]-[DEBUG] negotiated protocol: TLSv1.2 2020-03-19 16:10:35,119 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:425)]-[DEBUG] negotiated cipher suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 2020-03-19 16:10:35,120 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:433)]-[DEBUG] peer principal: CN=demo.bazefield.com, O=Bazefield A/S, L=Porsgrunn, C=NO 2020-03-19 16:10:35,120 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:442)]-[DEBUG] peer alternative names: [demo.bazefield.com, www.demo.bazefield.com] 2020-03-19 16:10:35,121 [org.apache.http.conn.ssl.SSLConnectionSocketFactory.verifyHostname(SSLConnectionSocketFactory.java:446)]-[DEBUG] issuer principal: CN=DigiCert SHA2 Secure Server CA, O=DigiCert Inc, C=US 2020-03-19 16:10:35,126 [org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:145)]-[DEBUG] Connection established 10.77.34.212:52558\u003c-\u003e212.33.148.80:443 2020-03-19 16:10:35,126 [org.apache.http.impl.conn.LoggingManagedHttpClientConnection.setSocketTimeout(LoggingManagedHttpClientConnection.java:90)]-[DEBUG] http-outgoing-0: set socket timeout to 3000 main, setSoTimeout(3000) called 2020-03-19 16:10:35,126 [org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:255)]-[DEBUG] Executing request POST /bazefield.services/api/oauth2/token HTTP/1.1 2020-03-19 16:10:35,126 [org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:260)]-[DEBUG] Target auth state: UNCHALLENGED 2020-03-19 16:10:35,127 [org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:266)]-[DEBUG] Proxy auth state: UNCHALLENGED 线索断了之后，只能通过抓包的方式看看究竟发生了什么。这里要出现今天讲的主角wireshark，通过这个强大的工具进行抓包，增加ip和ssl的filter （ip.addr==xxx.yy.zzz.80 and ssl）之后可以看到与目标地址的通讯包。但是，由于是https，包中的流量是加密的，并不能进行分析。于是，如何解密抓取的https流量成为关键。\n解密之前，首先要了解https的基本流程。这个网上有很多描述详细的文章，这边就不赘述。简单说一下，加密是通过指定的加密方法，结合客户端与服务端之间交换的两个随机数，再加上客户端用服务端提供证书上的public key加密的pre-master这个参数（外界是不知道这个参数的，这个参数由客户端生成，经过公钥加密后，只有服务端知道这个参数是什么），生成一个对称加密密钥。在握手结束后，客户端和服务端之间的通讯流量是采用对称加密算法来加密的，而加密的密钥是有握手阶段交换的随机数random_1，random_2以及pre-master和指定的加密算法生成的。这个过程中，最重要的一个参数就是pre-master，其他的参数都是可以通过抓包得到的。因此，如果能够拿到这个pre-master，那么就可以解密wireshark抓取的https流量。\n在前面所说的场景中，我们是客户端，无法知道服务端提供证书的私钥，因此不能从wireshark抓取的包中解密来获得pre-master。但是，我们在代码中所做的请求是通过Apache提供的httpclient完成的，可以在启动时添加vmoption参数-Djavax.net.debug=ssl,keygen来获得tls连接中的一些重要参数。下面是建立连接过程中打印出的部分参数\n*** ECDH ServerKeyExchange Signature Algorithm SHA512withRSA Server key: Sun EC public key, 256 bits public x coord: 82734322831099238985881665140172758067838155879895358323075425906443044790736 public y coord: 88453306709588242368663096476921278570527038619007749416185523277612481734068 parameters: secp256r1 [NIST P-256, X9.62 prime256v1] (1.2.840.10045.3.1.7) main, READ: TLSv1.2 Handshake, length = 4 check handshake state: server_hello_done[14] update handshake state: server_hello_done[14] upcoming handshake states: client certificate[11](optional) upcoming handshake states: client_key_exchange[16] upcoming handshake states: certificate_verify[15](optional) upcoming handshake states: client change_cipher_spec[-1] upcoming handshake states: client finished[20] upcoming handshake states: server change_cipher_spec[-1] upcoming handshake states: server finished[20] *** ServerHelloDone *** ECDHClientKeyExchange ECDH Public value: { 4, 18, 97, 2, 120, 116, 117, 129, 244, 110, 148, 192, 162, 71, 24, 69, 246, 200, 73, 114, 107, 103, 78, 70, 2, 79, 17, 20, 45, 67, 93, 228, 228, 60, 65, 251, 250, 234, 176, 208, 160, 199, 120, 131, 47, 25, 153, 74, 54, 32, 67, 29, 203, 96, 214, 30, 217, 240, 131, 124, 21, 160, 217, 161, 225 } update handshake state: client_key_exchange[16] upcoming handshake states: certificate_verify[15](optional) upcoming handshake states: client change_cipher_spec[-1] upcoming handshake states: client finished[20] upcoming handshake states: server change_cipher_spec[-1] upcoming handshake states: server finished[20] main, WRITE: TLSv1.2 Handshake, length = 70 SESSION KEYGEN: PreMaster Secret: 0000: 1B 26 6E 26 56 BB C2 7B C3 37 7B 3F 75 59 EA AC .\u0026n\u0026V....7.?uY.. 0010: 25 53 D1 0E 43 F2 85 49 31 FC 4A 98 C5 56 2C E1 %S..C..I1.J..V,. CONNECTION KEYGEN: Client Nonce: 0000: 5E 73 28 FA 0F 1A 88 82 6D 91 5D 50 0E BC 6B 87 ^s(.....m.]P..k. 0010: C5 DD 80 83 AB F7 5E 53 45 CB 34 9B C9 CE 16 02 ......^SE.4..... Server Nonce: 0000: F1 47 01 E9 55 FE 68 35 6F 43 F4 21 80 30 E9 81 .G..U.h5oC.!.0.. 0010: 6D 02 E5 DB B8 67 76 39 60 A3 42 D5 1F 43 32 6C m....gv9`.B..C2l Master Secret: 0000: 8B E2 88 59 42 7A EE F3 5F EC 25 B0 63 6A FC 91 ...YBz.._.%.cj.. 0010: 28 2E A3 70 47 63 19 E0 F5 DB 8D 68 64 77 43 91 (..pGc.....hdwC. 0020: 84 A4 A2 2B 1F 87 91 9D 02 76 EB 55 8A 69 65 BC ...+.....v.U.ie. ... no MAC keys used for this cipher Client write key: 0000: 44 19 21 EE 46 D5 D3 88 06 C1 6B 4A CF 4D A9 36 D.!.F.....kJ.M.6 0010: 21 BA F1 EE 1A C0 A2 60 C2 3B 18 89 32 A3 59 CA !......`.;..2.Y. Server write key: 0000: 34 C3 40 A7 20 0F 33 9D 19 2E 02 2D 4C 4E 80 30 4.@. .3....-LN.0 0010: 26 25 31 8A 08 DD D5 F0 F4 86 40 03 56 6A F1 D2 \u0026%1.......@.Vj.. Client write IV: 0000: 54 61 92 79 Ta.y Server write IV: 0000: 15 62 81 55 .b.U 这里我们所要的pre-master就是Clinent Nounce , Master Secret hex值的组合，最后的把它们存在一个sslkey.log文件中，格式如下（手动操作很简单，也可以参考一个python脚本来操作）\nCLIENT_RANDOM 5E731E001D49FA112BAF6B0CFFD8EF5C15DF90B27AE6516DFB83FBA484875ECD 1E53B5AFA6925E8E6B594F48C0BCAF64FDCDE60CA2610EBF6693065A4929E096E8287F9172C1D91CCC8134D2DB1370B4\n##!/usr/bin/env python import re import sys def extract_data_from_line(line): m = re.match('\\d+:([ 0-9A-F]{51}) .*', line) if m: return m.group(1).replace(' ', '') else: raise line def main(): f = open(\"debug.txt\", \"r\") parsing_mastersecret_line = 0 parsing_clientnonce_line = 0 for line in f.readlines(): if parsing_mastersecret_line: parsing_mastersecret_line += 1 if parsing_clientnonce_line: parsing_clientnonce_line += 1 if line == 'Client Nonce:\\n': parsing_clientnonce_line = 1 cn = \"\" if 2 \u003c= parsing_clientnonce_line \u003c= 3: cn = cn + extract_data_from_line(line) if line == 'Master Secret:\\n': parsing_mastersecret_line = 1 ms = \"\" if 2 \u003c= parsing_mastersecret_line \u003c= 4: ms = ms + extract_data_from_line(line) if 5 == parsing_mastersecret_line: print('CLIENT_RANDOM', cn, ms) if __name__ == '__main__': sys.exit(main()) 获得了这个重要的pre-master参数后，就可以在wireshark中指定tls的pre-master-secret 文件的名字，于是可以解密https流量。\n回归到要解决的问题，可以发现报出了这样的错误：\nFrame 84: 538 bytes on wire (4304 bits), 538 bytes captured (4304 bits) on interface \\Device\\NPF_{1E884C5A-1654-4DF6-A7E8-01A37930B33B}, id 0 Ethernet II, Src: a2:39:20:00:08:00 (a2:39:20:00:08:00), Dst: 0f:00:08:00:00:00 (0f:00:08:00:00:00) Internet Protocol Version 4, Src: xxx.yy.zzz.80, Dst: aa.bb.cc.dd Transmission Control Protocol, Src Port: 443, Dst Port: 63636, Seq: 4343, Ack: 1042, Len: 484 Transport Layer Security Hypertext Transfer Protocol HTTP/1.1 400 Bad Request\\r\\n [Expert Info (Chat/Sequence): HTTP/1.1 400 Bad Request\\r\\n] [HTTP/1.1 400 Bad Request\\r\\n] [Severity level: Chat] [Group: Sequence] Response Version: HTTP/1.1 Status Code: 400 [Status Code Description: Bad Request] Response Phrase: Bad Request Date: Thu, 19 Mar 2020 06:50:21 GMT\\r\\n Server: Apache\\r\\n Cache-Control: private\\r\\n Content-Type: text/html; charset=utf-8\\r\\n X-AspNet-Version: 4.0.30319\\r\\n X-UA-Compatible: IE=edge\\r\\n Vary: Accept-Encoding\\r\\n Content-Encoding: gzip\\r\\n Content-Length: 168\\r\\n [Content length: 168] Connection: close\\r\\n \\r\\n [HTTP response 1/1] [Time since request: 0.325101000 seconds] [Request in frame: 80] [Request URI: https://xxx.yyy.com/mmm.services/api/oauth2/token] Content-encoded entity body (gzip): 168 bytes -\u003e 191 bytes File Data: 191 bytes Line-based text data: text/html (1 lines) Error: SerializationException: Type definitions should start with a '{', expecting serialized type 'TokenRequest', got string starting with: client_secret=6e18dc44-1171-48b2-8380-66071231831e 通过错误可以猜测到和json的结构有关，于是找到代码中的相关部分进行更正，原来的请求就可以顺利执行了。\n参考文献 https://zhuanlan.zhihu.com/p/44786952，\nhttps://timothybasanov.com/2016/05/26/java-pre-master-secret.html\n","description":"","tags":null,"title":"Java中如何用wireshark抓取https","uri":"/posts/java-wireshark-https/"}]
